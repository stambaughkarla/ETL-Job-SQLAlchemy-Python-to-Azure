{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Xr/mwOm0ZvDVDHH2a5a2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stambaughkarla/ETL-Job-SQLAlchemy-Python-to-Azure/blob/main/Reservations_ETL_Job.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a49sXK_8neV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "import sqlalchemy as db\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Creating a Pipeline for an Azure Database Connection"
      ],
      "metadata": {
        "id": "bizd5VgEry_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyodbc\n",
        "!curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "!curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "!apt-get update\n",
        "!ACCEPT_EULA=Y apt-get -y install msodbcsql18\n",
        "!odbcinst -q -d -n \"ODBC Driver 18 for SQL Server\"\n",
        "os.environ['ODBCINI'] = '/etc/odbc.ini'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT8_O_E2xy5h",
        "outputId": "0e3f4632-e301-43a6-a6da-d5ad872604ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyodbc\n",
            "  Downloading pyodbc-5.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading pyodbc-5.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/336.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m327.7/336.0 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.0/336.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyodbc\n",
            "Successfully installed pyodbc-5.2.0\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "100   983  100   983    0     0   1923      0 --:--:-- --:--:-- --:--:--  1927\n",
            "OK\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    88  100    88    0     0    648      0 --:--:-- --:--:-- --:--:--   651\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:8 https://packages.microsoft.com/ubuntu/22.04/prod jammy InRelease [3,632 B]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,531 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,192 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,626 kB]\n",
            "Get:17 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main amd64 Packages [174 kB]\n",
            "Get:18 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main armhf Packages [16.0 kB]\n",
            "Get:19 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main all Packages [1,243 B]\n",
            "Get:20 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main arm64 Packages [40.8 kB]\n",
            "Get:21 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\n",
            "Fetched 18.2 MB in 4s (4,559 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "W: https://packages.microsoft.com/ubuntu/22.04/prod/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  odbcinst unixodbc\n",
            "The following NEW packages will be installed:\n",
            "  msodbcsql18 odbcinst unixodbc\n",
            "0 upgraded, 3 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 792 kB of archives.\n",
            "After this operation, 164 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 odbcinst amd64 2.3.9-5ubuntu0.1 [9,930 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 unixodbc amd64 2.3.9-5ubuntu0.1 [26.7 kB]\n",
            "Get:3 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main amd64 msodbcsql18 amd64 18.4.1.1-1 [755 kB]\n",
            "Fetched 792 kB in 0s (9,350 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package odbcinst.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../odbcinst_2.3.9-5ubuntu0.1_amd64.deb ...\n",
            "Unpacking odbcinst (2.3.9-5ubuntu0.1) ...\n",
            "Selecting previously unselected package unixodbc.\n",
            "Preparing to unpack .../unixodbc_2.3.9-5ubuntu0.1_amd64.deb ...\n",
            "Unpacking unixodbc (2.3.9-5ubuntu0.1) ...\n",
            "Selecting previously unselected package msodbcsql18.\n",
            "Preparing to unpack .../msodbcsql18_18.4.1.1-1_amd64.deb ...\n",
            "Unpacking msodbcsql18 (18.4.1.1-1) ...\n",
            "Setting up odbcinst (2.3.9-5ubuntu0.1) ...\n",
            "Setting up unixodbc (2.3.9-5ubuntu0.1) ...\n",
            "Setting up msodbcsql18 (18.4.1.1-1) ...\n",
            "odbcinst: Driver installed. Usage count increased to 1. \n",
            "    Target directory is /etc\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "[ODBC Driver 18 for SQL Server]\n",
            "Description=Microsoft ODBC Driver 18 for SQL Server\n",
            "Driver=/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.4.so.1.1\n",
            "UsageCount=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting it all Together"
      ],
      "metadata": {
        "id": "Xmdx0aORsCwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tabs_from_xlsx(file_path):\n",
        "    xls = pd.ExcelFile(file_path)\n",
        "    dfs = {}\n",
        "    for sheet_name in xls.sheet_names:\n",
        "        df = xls.parse(sheet_name, index_col=None)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "        dfs[sheet_name] = df\n",
        "\n",
        "    return dfs\n"
      ],
      "metadata": {
        "id": "foauAht6uCL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_sql(eng, name):\n",
        "  data = pd.read_sql(f'select * from {name}', eng)\n",
        "  print(\"reading first few rows\")\n",
        "  print(data.head())\n",
        "  print(\"Succeffuly Extracted Data from Azure\")\n",
        "  raw_data = data\n",
        "  return raw_data"
      ],
      "metadata": {
        "id": "KJ_YRntTfMG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformations(res,users,prop):\n",
        "  merged_df_with_users = res.merge(users, how='left', on='Email')\n",
        "  merged_df_with_users.rename(columns= {\"Id\":\"CustomerID\"}, inplace= True  )\n",
        "  merged_df_all = merged_df_with_users.merge(prop, how='left', on='PropertyNumber')\n",
        "  merged_df_all.head()\n",
        "\n",
        "  reservation_columns = [\n",
        "      'PropertyID', 'CustomerID', 'Start Date', 'End Date',\n",
        "      'GuestsAllowed', 'WeekdayPrice', 'WeekendPrice_x', 'CleaningFee_x',\n",
        "      'DiscountRate_y', 'ConfirmationNumber', 'ReservationStatus'\n",
        "  ]\n",
        "\n",
        "  reservations_subset = merged_df_all[reservation_columns]\n",
        "  reservations_subset.head()\n",
        "  reservations_subset.rename(columns= { \"Start Date\":\"CheckIn\", \"End Date\":\"CheckOut\" , \"GuestsAllowed\": \"NumOfGuests\", \"CleaningFee_x\": \"CleaningFee\" }, inplace= True  )\n",
        "  reservations_subset.rename(columns= {\"WeekendPrice_x\":\"WeekendPrice\"}, inplace= True  )\n",
        "  reservations_subset.rename(columns= {\"DiscountRate_y\":\"DiscountRate\"}, inplace= True  )\n",
        "  reservations_subset.ReservationStatus=reservations_subset.ReservationStatus.map({\"Valid\":1, \"Cancelled\":0})\n",
        "  reservations_subset.DiscountRate=reservations_subset.DiscountRate.fillna(0)\n",
        "  reservations_subset.head()\n",
        "  return reservations_subset\n"
      ],
      "metadata": {
        "id": "-BNVBwD49ZL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_sql(DATA, engine, table_output):\n",
        "    try:\n",
        "\n",
        "        if 'Unnamed: 0' in DATA.columns:\n",
        "            DATA.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "        # Load data into SQL\n",
        "        DATA.to_sql(\n",
        "            name=table_output,\n",
        "            con=engine,\n",
        "            index=False,\n",
        "            if_exists=\"append\"\n",
        "        )\n",
        "        print(\"===== Successfully added to Database =====\\n\")\n",
        "    except Exception as e:\n",
        "        print(\"Error in Load: Error loading to SQL\")\n",
        "        print(\"Error Details:\", e)\n"
      ],
      "metadata": {
        "id": "GjtEvLh8yZvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Main():\n",
        "\n",
        "  table_output = 'Reservations'\n",
        "  eng = db.create_engine(\n",
        "    \"mssql+pyodbc://MISAdmin:Password123@fa24group25finalproject.database.windows.net:1433/fa24group25finalproject?driver=ODBC+Driver+18+for+SQL+Server&Encrypt=yes&TrustServerCertificate=no&Connection+Timeout=30\")\n",
        "  #Extract from excel\n",
        "  dfs = extract_tabs_from_xlsx('SeedingDataBevoBnB.xlsx')\n",
        "  res = dfs['Reservations']\n",
        "  res.rename(columns= {\"Customer\":\"Email\"}, inplace= True  )\n",
        "  #Extract from Azure\n",
        "  users=extract_from_sql(eng, 'AspNetUsers')\n",
        "  prop = extract_from_sql2(eng, 'Properties')\n",
        "  #Transform\n",
        "  reservations_subset = transformations(res,users,prop)\n",
        "  print(\"===== Successfully Tranformed Data =====\\n\")\n",
        "  load_to_sql(reservations_subset,eng, table_output)\n",
        "  print(\"===== Successfully Closed all Remote Connections =====\\n\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  Main()"
      ],
      "metadata": {
        "id": "NLoTg-nDsG3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04168f68-d0ed-425e-d7e2-60efbcdc8fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Successfully Tranformed Data =====\n",
            "\n"
          ]
        }
      ]
    }
  ]
}